[#publish-website]
== Publish website

We now copy the results of the Antora website generation over to the `causeway-site` repo:

* in the `causeway-site` repo, check out the `asf-site` branch:
+
[source,bash,subs="attributes+"]
----
cd ../causeway-site

git checkout asf-site
git pull --ff-only
----

* still in the `causeway-site` repo, run the `copyover.sh` script:
+
[source,bash,subs="attributes+"]
----
sh copyover.sh
----
+
This deletes all the files in `content/` _except_ for the `schema` and `versions` directories, and copies the generated Antora site to `causeway-site` repo's `contents` directory:
+
[source,bash,subs="attributes+"]
----
#!/usr/bin/env bash
pushd content
for a in $(ls -1 | grep -v schema | grep -v versions)
do
    rm -rf $a
done
popd

pushd ../causeway
cp -Rf antora/target/site/* ../causeway-site/content/.
popd

git add .
----

* Commit the changes and preview:
+
[source,bash,subs="attributes+"]
----
git commit -m "updates website"

sh preview.sh
----

* If everything looks ok, then push the changes to make live, and switch back to the `causeway` repo:
+
[source,bash,subs="attributes+"]
----
git push origin asf-site
----

[#update-the-algolia-search-index]
== Update the Algolia search index

We use link:https://docsearch.algolia.com[Algolia] to build our search index.

* If required, create a `algolia.env` file holding the `APP_ID` and the admin `API_KEY`, in the root of `causeway-site`; see xref:comguide:ROOT:algolia-search.adoc#create-the-algolia-env-file[appendix] for details.

* If required, update the `algolia-config.json` file; see xref:comguide:ROOT:algolia-search.adoc#create-the-crawler-config[appendix] for details.
+
In particular, update the `stop_urls` property with any paths that should not be crawled.
+
NOTE: Our policy is to only index the most recent version.
This avoids lots of duplication in the index; previous versions of the page are easily accessible.

* Use the Algolia-provided link:https://hub.docker.com/r/algolia/docsearch-scraper[docker image] to crawl the web pages and create the search index:
+
[source,bash]
----
pushd content
docker run -it --env-file=../algolia.env -e "CONFIG=$(cat ../algolia-config.json | jq -r tostring)" algolia/docsearch-scraper:v1.16.0
popd
----
+
This posts the index up to the link:https://algolia.com[Algolia] site.
+
NOTE: Further documentation on the crawler can be found link:as per https://docsearch.algolia.com/docs/run-your-own/#run-the-crawl-from-the-docker-image[here]; additional config options for the crawler can be found link:https://www.algolia.com/doc/api-reference/crawler/[here].

